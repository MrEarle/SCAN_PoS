{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.models.lstm import Seq2SeqAttentionLSTM, Seq2SeqLSTM\n",
    "from src.data.scan import (\n",
    "    MAX_SEQUENCE_LENGTH,\n",
    "    IN_VOCAB_FILE,\n",
    "    POS_VOCAB_SIZE,\n",
    "    OUT_VOCAB_SIZE,\n",
    "    IN_VOCAB_SIZE,\n",
    "    POS_VOCAB_FILE,\n",
    "    OUT_VOCAB_FILE,\n",
    ")\n",
    "from src.utils.constants import ACTION_INPUT_NAME, ACTION_OUTPUT_NAME, COMMAND_INPUT_NAME, POS_OUTPUT_NAME, POS_INPUT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=IN_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "pos_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=POS_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "out_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=OUT_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "\n",
    "\n",
    "in_vectorizer.set_vocabulary(IN_VOCAB_FILE)\n",
    "pos_vectorizer.set_vocabulary(POS_VOCAB_FILE)\n",
    "out_vectorizer.set_vocabulary(OUT_VOCAB_FILE)\n",
    "\n",
    "out_voc = out_vectorizer.get_vocabulary()\n",
    "pos_voc = pos_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = \"<sos> jump and run <eos>\"\n",
    "model_pos = \"NOUN CONJ VERB\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))\n",
    "model_pos_vec = pos_vectorizer(tf.convert_to_tensor([model_pos, model_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2806e7a8580>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 200\n",
    "hidden_layers = 1\n",
    "include_pos_tag = \"input\"\n",
    "use_attention = True\n",
    "\n",
    "Model = Seq2SeqAttentionLSTM if use_attention else Seq2SeqLSTM\n",
    "\n",
    "model = Model(\n",
    "    hidden_size=hidden_size,\n",
    "    hidden_layers=hidden_layers,\n",
    "    include_pos_tag=include_pos_tag,\n",
    "    teacher_forcing=0,\n",
    ")\n",
    "\n",
    "pre_res = model({COMMAND_INPUT_NAME: model_in_vec, POS_INPUT_NAME: model_pos_vec}, training=False)\n",
    "checkpoint_path = f\"snap\\h_size({hidden_size})-h_layers({hidden_layers})-dropout(0.1)-pos({include_pos_tag}){'-attention' if use_attention else ''}/best_action_accuracy\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = \"<sos> jump and run <eos>\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> I_TURN_LEFT I_RUN I_RUN I_RUN I_RUN <eos>\n"
     ]
    }
   ],
   "source": [
    "model_in = \"<sos> run around left <eos>\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))\n",
    "pre_res = model({COMMAND_INPUT_NAME: model_in_vec, POS_INPUT_NAME: model_pos_vec}, training=False)\n",
    "\n",
    "actions = tf.argmax(pre_res[ACTION_OUTPUT_NAME][0], axis=-1)\n",
    "# pos = tf.argmax(pre_res[POS_OUTPUT_NAME][0], axis=-1)\n",
    "\n",
    "actions = \" \".join([out_voc[i] for i in actions]).strip()\n",
    "# pos = \" \".join([pos_voc[i] for i in pos]).strip()\n",
    "\n",
    "print(actions)\n",
    "# print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e693c1a5948535cd0a63fa6f245053b78120c9e0380f8ba709fae81d9dc1df8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
