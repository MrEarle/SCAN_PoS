{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.models.lstm import Seq2SeqAttentionLSTM, Seq2SeqLSTM\n",
    "from src.data.scan import (\n",
    "    MAX_SEQUENCE_LENGTH,\n",
    "    IN_VOCAB_FILE,\n",
    "    POS_VOCAB_SIZE,\n",
    "    OUT_VOCAB_SIZE,\n",
    "    IN_VOCAB_SIZE,\n",
    "    POS_VOCAB_FILE,\n",
    "    OUT_VOCAB_FILE,\n",
    "    load_dataset,\n",
    "    get_add_pos_tag,\n",
    "    DS_POS_FILE,\n",
    "    add_sos_eos,\n",
    "    get_vectorizer,\n",
    "    get_final_map_function\n",
    ")\n",
    "from src.utils.constants import ACTION_INPUT_NAME, ACTION_OUTPUT_NAME, COMMAND_INPUT_NAME, POS_OUTPUT_NAME, POS_INPUT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def filter(x, *_):\n",
    "    return K.any(K.equal(x, 'jump'))\n",
    "\n",
    "def get_dataset(experiment: str):\n",
    "    train, test = load_dataset(experiment, split=[\"train\", \"test\"])\n",
    "\n",
    "    # Split dataset into tuples\n",
    "    train = train.map(lambda x: (x[\"commands\"], x[\"actions\"]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test = test.map(lambda x: (x[\"commands\"], x[\"actions\"]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    train = train.filter(filter)\n",
    "    # test = test.filter(filter)\n",
    "    \n",
    "    add_pos_tag = get_add_pos_tag(DS_POS_FILE)\n",
    "\n",
    "    # Add pos tag to dataset\n",
    "    train = train.map(add_pos_tag, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test = test.map(add_pos_tag, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Add <sos> and <eos> to dataset\n",
    "    train = train.map(add_sos_eos, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test = test.map(add_sos_eos, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    vectorize_text, in_vectorizer, pos_vectorizer, out_vectorizer = get_vectorizer()\n",
    "\n",
    "    # Vectorize dataset\n",
    "    train = train.map(\n",
    "        lambda x, p, y: tf.py_function(vectorize_text, inp=(x, p, y), Tout=(tf.int64, tf.int64, tf.int64)),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    test = test.map(\n",
    "        lambda x, p, y: tf.py_function(vectorize_text, inp=(x, p, y), Tout=(tf.int64, tf.int64, tf.int64)),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "\n",
    "    return train, test, (in_vectorizer, pos_vectorizer, out_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=IN_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "pos_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=POS_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "out_vectorizer = layers.TextVectorization(\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH, output_mode=\"int\", max_tokens=OUT_VOCAB_SIZE, standardize=None\n",
    ")\n",
    "\n",
    "\n",
    "in_vectorizer.set_vocabulary(IN_VOCAB_FILE)\n",
    "pos_vectorizer.set_vocabulary(POS_VOCAB_FILE)\n",
    "out_vectorizer.set_vocabulary(OUT_VOCAB_FILE)\n",
    "\n",
    "in_voc = in_vectorizer.get_vocabulary()\n",
    "out_voc = out_vectorizer.get_vocabulary()\n",
    "pos_voc = pos_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = \"<sos> jump and run <eos>\"\n",
    "model_pos = \"NOUN CONJ VERB\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))\n",
    "model_pos_vec = pos_vectorizer(tf.convert_to_tensor([model_pos, model_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d7a665d340>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "hidden_layers = 1\n",
    "include_pos_tag = \"aux\"\n",
    "use_attention = True\n",
    "\n",
    "Model = Seq2SeqAttentionLSTM if use_attention else Seq2SeqLSTM\n",
    "\n",
    "model = Model(\n",
    "    hidden_size=hidden_size,\n",
    "    hidden_layers=hidden_layers,\n",
    "    include_pos_tag=include_pos_tag,\n",
    "    teacher_forcing=0,\n",
    ")\n",
    "\n",
    "pre_res = model({COMMAND_INPUT_NAME: model_in_vec, POS_INPUT_NAME: model_pos_vec}, training=False)\n",
    "checkpoint_path = f\"snap/simple-h_size({hidden_size})-h_layers({hidden_layers})-dropout(0.1){f'-pos({include_pos_tag})' if include_pos_tag else ''}{'-attention' if use_attention else ''}/best_action_accuracy\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = \"<sos> jump and run <eos>\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In vocabulary: {0: '', 1: '[UNK]', 2: '<sos>', 3: '<eos>', 4: 'run', 5: 'opposite', 6: 'right', 7: 'after', 8: 'turn', 9: 'left', 10: 'twice', 11: 'around', 12: 'thrice', 13: 'walk', 14: 'jump', 15: 'and', 16: 'look'}\n",
      "Pos vocabulary: {0: '', 1: '[UNK]', 2: '<sos>', 3: '<eos>', 4: 'ADV', 5: 'CNJ', 6: 'DIR', 7: 'MOD', 8: 'VRB'}\n",
      "Out vocabulary: {0: '', 1: '[UNK]', 2: '<sos>', 3: '<eos>', 4: 'I_TURN_LEFT', 5: 'I_TURN_RIGHT', 6: 'I_RUN', 7: 'I_WALK', 8: 'I_JUMP', 9: 'I_LOOK'}\n"
     ]
    }
   ],
   "source": [
    "train, test, _ = get_dataset(\"simple\")\n",
    "final_map_fn = get_final_map_function(\n",
    "    include_pos_tag=\"aux\",\n",
    "    teacher_forcing=False,\n",
    ")\n",
    "train = train.map(final_map_fn)\n",
    "test = test.map(final_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(val, model):\n",
    "    x, y = val\n",
    "    print(x.keys(), x[COMMAND_INPUT_NAME].shape)\n",
    "    print(y.keys())\n",
    "    res = model(x, training=False)\n",
    "    \n",
    "    in_seq1 = x[COMMAND_INPUT_NAME][0]\n",
    "    in_seq1 = \" \".join([in_voc[i] for i in in_seq1]).strip()\n",
    "\n",
    "    actions1 = tf.argmax(res[ACTION_OUTPUT_NAME][0], axis=-1)\n",
    "    actions1 = \" \".join([out_voc[i] for i in actions1]).strip()\n",
    "    actions1 = actions1.split('<eos>')[0]\n",
    "\n",
    "    in_seq2 = x[COMMAND_INPUT_NAME][1]\n",
    "    in_seq2 = \" \".join([in_voc[i] for i in in_seq2]).strip()\n",
    "\n",
    "    actions2 = tf.argmax(res[ACTION_OUTPUT_NAME][1], axis=-1)\n",
    "    actions2 = \" \".join([out_voc[i] for i in actions2]).strip()\n",
    "    actions2 = actions2.split('<eos>')[0]\n",
    "\n",
    "    return in_seq1, actions1, in_seq2, actions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stuff(ds, model):\n",
    "    z = ds.take(10).batch(2)\n",
    "    for vals in z:\n",
    "        print(vals)\n",
    "        i, o, i2, o2 = get_pred(vals, model)\n",
    "        print(i)\n",
    "        print(o)\n",
    "        print(i2)\n",
    "        print(o2)\n",
    "        yield\n",
    "    print('wtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stuff(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TakeDataset' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17092/1977886155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17092/2325000902.py\u001b[0m in \u001b[0;36mstuff\u001b[1;34m(ds, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstuff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mget_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvals\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TakeDataset' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_embedding'])\n",
      "dict_keys(['action_output', 'pos_output'])\n",
      "[ 2 14  3  0  0  0  0  0  0  0  0  0]\n",
      "<sos> jump <eos>\n",
      "<sos> <sos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
     ]
    }
   ],
   "source": [
    "i, o, i2, o2 = get_pred(ds, model)\n",
    "print(i)\n",
    "print(o)\n",
    "print(i2)\n",
    "print(o2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> I_TURN_LEFT I_WALK I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
     ]
    }
   ],
   "source": [
    "model_in = \"<sos> run around left after walk left <eos>\"\n",
    "\n",
    "model_in_vec = in_vectorizer(tf.convert_to_tensor([model_in, model_in]))\n",
    "pre_res = model({COMMAND_INPUT_NAME: model_in_vec, POS_INPUT_NAME: model_pos_vec}, training=False)\n",
    "\n",
    "actions = tf.argmax(pre_res[ACTION_OUTPUT_NAME][0], axis=-1)\n",
    "# pos = tf.argmax(pre_res[POS_OUTPUT_NAME][0], axis=-1)\n",
    "\n",
    "actions = \" \".join([out_voc[i] for i in actions]).strip()\n",
    "# pos = \" \".join([pos_voc[i] for i in pos]).strip()\n",
    "\n",
    "print(actions)\n",
    "# print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e693c1a5948535cd0a63fa6f245053b78120c9e0380f8ba709fae81d9dc1df8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
